{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14488715,"sourceType":"datasetVersion","datasetId":9252113}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================================================\n# MULTIPLEX — MEMORY vs AMNESIC (corr MAX) — OPTIMISÉ\n# - Graphes FIXES par (topo,z,corr)\n# - Influence layers précomputées (BFS cutoff Lmax)\n# - Numba: AUCUNE allocation dans la boucle\n# - Même seeds IC pour comparer amnesic vs memory\n# =========================================================\n\nimport numpy as np\nimport networkx as nx\nimport pandas as pd\nimport os, time\nfrom collections import deque\nfrom numba import njit\nfrom joblib import Parallel, delayed\n\n# ------------------------\n# GRAPH BUILDERS\n# ------------------------\ndef make_graph(topo, N, z, seed):\n    if topo == \"BA\":\n        m = int(z / 2)\n        return nx.barabasi_albert_graph(N, m, seed=seed)\n    elif topo == \"ER\":\n        return nx.erdos_renyi_graph(N, z / (N - 1), seed=seed)\n    else:\n        raise ValueError(\"topo must be 'BA' or 'ER'\")\n\ndef make_influence_graph(G_g, corr, N, seed_perm=777):\n    \"\"\"corr=max => G_i = G_g ; corr=nulle => permutation FIXE.\"\"\"\n    if corr == \"max\":\n        return G_g\n    rng = np.random.default_rng(seed_perm)\n    perm = np.arange(N, dtype=np.int32)\n    rng.shuffle(perm)\n    mapping = {int(i): int(perm[i]) for i in range(N)}\n    return nx.relabel_nodes(G_g, mapping)\n\ndef graph_to_csr(G):\n    \"\"\"CSR-like adjacency for fast numba iteration.\"\"\"\n    G = nx.convert_node_labels_to_integers(G)\n    N = G.number_of_nodes()\n    adj_f = []\n    adj_o = [0]\n    for i in range(N):\n        neigh = list(G.neighbors(i))\n        adj_f.extend(neigh)\n        adj_o.append(len(adj_f))\n    adj_f = np.array(adj_f, dtype=np.int32)\n    adj_o = np.array(adj_o, dtype=np.int32)\n    deg = (adj_o[1:] - adj_o[:-1]).astype(np.int32)\n    return adj_f, adj_o, deg\n\ndef build_influence_layers_bfs(G_i, N, Lmax):\n    \"\"\"\n    Precompute influence neighbors up to distance Lmax.\n    Returns:\n      inf_indices: (Lmax, N, N) int32 (ok for N=500)\n      inf_counts : (Lmax, N) int32\n    \"\"\"\n    adj = [list(G_i.neighbors(i)) for i in range(N)]\n    inf_indices = np.zeros((Lmax, N, N), dtype=np.int32)\n    inf_counts  = np.zeros((Lmax, N), dtype=np.int32)\n\n    for src in range(N):\n        dist = np.full(N, -1, dtype=np.int32)\n        dist[src] = 0\n        q = deque([src])\n\n        while q:\n            u = q.popleft()\n            du = dist[u]\n            if du == Lmax:\n                continue\n            for v in adj[u]:\n                if dist[v] == -1:\n                    dist[v] = du + 1\n                    q.append(v)\n\n        for j in range(N):\n            d = dist[j]\n            if 0 < d <= Lmax:\n                l = d - 1\n                c = inf_counts[l, src]\n                inf_indices[l, src, c] = j\n                inf_counts[l, src] += 1\n\n    return inf_indices, inf_counts\n\n# ------------------------\n# NUMBA CORE (NO ALLOCS IN LOOP)\n# ------------------------\n@njit(cache=True, fastmath=True)\ndef run_simulation_memory_vs_amnesic_fast(\n    adj_f, adj_o, deg_f,\n    inf_indices, inf_counts,\n    alpha_weights,\n    theta, b,\n    steps,\n    vigilance_mode,  # 0 amnesic / 1 memory(sticky)\n    cost_c,\n    seed\n):\n    np.random.seed(seed)\n\n    N = deg_f.shape[0]\n    L = alpha_weights.shape[0]\n\n    strat = np.random.randint(0, 2, N).astype(np.float64)  # 1=C, 0=D\n\n    vig = np.zeros(N, dtype=np.float64)\n    for i in range(N):\n        if strat[i] == 1.0 and np.random.random() < 0.5:\n            vig[i] = 1.0\n\n    # prealloc\n    influences = np.empty(N, dtype=np.float64)\n    T_eff      = np.empty(N, dtype=np.float64)\n    payoffs    = np.empty(N, dtype=np.float64)\n    new_strat  = np.empty(N, dtype=np.float64)\n\n    # stop criterion (rolling std)\n    history_window = 300\n    burn_in = 1200\n    tol_std = 8e-4\n    history_c = np.zeros(history_window, dtype=np.float64)\n    filled = 0\n\n    for t in range(steps):\n\n        # A) Influence\n        for i in range(N):\n            I_i = 0.0\n            for l in range(L):\n                cnt = inf_counts[l, i]\n                if cnt > 0:\n                    s = 0.0\n                    for k in range(cnt):\n                        s += vig[inf_indices[l, i, k]]\n                    I_i += alpha_weights[l] * (s / cnt)\n            influences[i] = I_i\n\n        # B) Vigilance update\n        if vigilance_mode == 0:  # amnesic\n            for i in range(N):\n                if strat[i] == 1.0:\n                    vig[i] = 1.0 if influences[i] >= theta else 0.0\n                else:\n                    vig[i] = 0.0\n        else:  # sticky memory\n            for i in range(N):\n                if strat[i] == 0.0:\n                    vig[i] = 0.0\n                else:\n                    if vig[i] == 1.0:\n                        vig[i] = 1.0\n                    else:\n                        vig[i] = 1.0 if influences[i] >= theta else 0.0\n\n        # C) Payoffs\n        for i in range(N):\n            T_eff[i] = 1.0 + (b - 1.0) * (1.0 - influences[i])\n            payoffs[i] = 0.0\n\n        for i in range(N):\n            start = adj_o[i]\n            end = adj_o[i + 1]\n\n            if strat[i] == 1.0:\n                for idx in range(start, end):\n                    j = adj_f[idx]\n                    if strat[j] == 1.0:\n                        payoffs[i] += 1.0\n            else:\n                Ti = T_eff[i]\n                for idx in range(start, end):\n                    j = adj_f[idx]\n                    if strat[j] == 1.0:\n                        payoffs[i] += Ti\n\n        if cost_c > 0.0:\n            for i in range(N):\n                if vig[i] == 1.0:\n                    payoffs[i] -= cost_c\n\n        # D) Strategy update (PROPORTIONAL only, like your config)\n        for i in range(N):\n            new_strat[i] = strat[i]\n\n        for i in range(N):\n            start = adj_o[i]\n            end = adj_o[i + 1]\n            k_i = end - start\n            if k_i == 0:\n                continue\n\n            j = adj_f[start + np.random.randint(0, k_i)]\n            if payoffs[j] > payoffs[i]:\n                k_j = deg_f[j]\n                kmax = k_i if k_i > k_j else k_j\n                Te = T_eff[i] if T_eff[i] > T_eff[j] else T_eff[j]\n                phi = kmax * Te\n                if phi > 0.0:\n                    if np.random.random() < (payoffs[j] - payoffs[i]) / phi:\n                        new_strat[i] = strat[j]\n\n        for i in range(N):\n            strat[i] = new_strat[i]\n\n        # rho\n        rho = 0.0\n        for i in range(N):\n            rho += strat[i]\n        rho /= N\n\n        if rho <= 0.0 or rho >= 1.0:\n            mv = 0.0\n            for i in range(N):\n                mv += vig[i]\n            return rho, mv / N\n\n        history_c[t % history_window] = rho\n        if filled < history_window:\n            filled += 1\n\n        if t > burn_in and (t % 50 == 0) and (filled == history_window):\n            m = 0.0\n            for kk in range(history_window):\n                m += history_c[kk]\n            m /= history_window\n\n            v = 0.0\n            for kk in range(history_window):\n                d = history_c[kk] - m\n                v += d * d\n            v /= history_window\n\n            if np.sqrt(v) < tol_std:\n                mv = 0.0\n                for i in range(N):\n                    mv += vig[i]\n                return m, mv / N\n\n    # fallback\n    m = 0.0\n    for kk in range(filled if filled > 0 else 1):\n        m += history_c[kk]\n    m /= (filled if filled > 0 else 1)\n\n    mv = 0.0\n    for i in range(N):\n        mv += vig[i]\n    return m, mv / N\n\n# ------------------------\n# CONFIG (same spirit as yours)\n# ------------------------\nN = 500\nREPS = 100\nsteps = 12000\n\ncorr = \"max\"\ncost_c = 0.0\nB_RANGE = np.around(np.arange(1.0, 2.1, 0.1), 1)\n\nTOPOS = [(\"BA\", 16)]\nthetas = [0.4]\nL_list = [4]\n\nOUTFILE = \"P2_2_MEMORY_vs_AMNESIC_corrMAX_cost0_prop_OPT.csv\"\nOUTFILE = \"P2_2_BA16_VÉRIFICATION.csv\"\n\n# seeds IC shared between modes\nBASE_SEED = 12345\nIC_SEEDS = np.array([BASE_SEED + 1000*r for r in range(REPS)], dtype=np.int64)\n\ndef one_ic(seed, adj_f, adj_o, deg_f, inf_idx_L, inf_cnt_L, alphas, theta, b, steps, mode, cost_c):\n    return run_simulation_memory_vs_amnesic_fast(\n        adj_f, adj_o, deg_f,\n        inf_idx_L, inf_cnt_L,\n        alphas,\n        float(theta), float(b),\n        int(steps),\n        int(mode),\n        float(cost_c),\n        int(seed)\n    )\n\n# ------------------------\n# Warmup compile\n# ------------------------\ndef warmup_compile():\n    Gtmp = make_graph(\"ER\", 60, 8, seed=0)\n    Gi = make_influence_graph(Gtmp, \"max\", 60, seed_perm=1)\n    af, ao, deg = graph_to_csr(Gtmp)\n    inf_idx, inf_cnt = build_influence_layers_bfs(Gi, 60, Lmax=2)\n    alphas = np.array([1.0], dtype=np.float64)\n\n    _ = run_simulation_memory_vs_amnesic_fast(\n        af, ao, deg,\n        inf_idx[:1], inf_cnt[:1],\n        alphas,\n        0.6, 1.4,\n        200,\n        0,\n        0.0,\n        0\n    )\n\nwarmup_compile()\n\n# ------------------------\n# RUN\n# ------------------------\nfor topo, z in TOPOS:\n    # FIXED graphs for this topo/z\n    Gg = make_graph(topo, N, z, seed=42)\n    Gi = make_influence_graph(Gg, corr=corr, N=N, seed_perm=777)\n\n    # precompute game CSR once\n    adj_f, adj_o, deg_f = graph_to_csr(Gg)\n\n    # precompute influence once up to max L\n    Lmax = max(L_list)\n    inf_idx_all, inf_cnt_all = build_influence_layers_bfs(Gi, N, Lmax=Lmax)\n\n    for theta in thetas:\n        for L in L_list:\n            inf_idx_L = inf_idx_all[:L]\n            inf_cnt_L = inf_cnt_all[:L]\n\n            alphas = np.array([0.5**l for l in range(L)], dtype=np.float64)\n            alphas /= np.sum(alphas)\n\n            for mode_name, mode_val in [(\"amnesic\", 0), (\"memory\", 1)]:\n                for b in B_RANGE:\n                    start = time.time()\n\n                    data = Parallel(n_jobs=-1)(\n                        delayed(one_ic)(\n                            int(IC_SEEDS[r]),\n                            adj_f, adj_o, deg_f,\n                            inf_idx_L, inf_cnt_L,\n                            alphas, theta, float(b), steps,\n                            mode_val, cost_c\n                        )\n                        for r in range(REPS)\n                    )\n\n                    rhos = np.array([x[0] for x in data], dtype=np.float64)\n                    vigs = np.array([x[1] for x in data], dtype=np.float64)\n\n                    pd.DataFrame([{\n                        \"Topo\": topo, \"Z\": z, \"Corr\": corr,\n                        \"Theta\": float(theta), \"L\": int(L), \"b\": float(b),\n                        \"Update\": \"proportional\", \"K\": np.nan,\n                        \"VigilanceMode\": mode_name, \"Cost\": float(cost_c),\n                        \"C_mean\": float(rhos.mean()), \"C_std\": float(rhos.std()),\n                        \"V_mean\": float(vigs.mean()), \"V_std\": float(vigs.std())\n                    }]).to_csv(OUTFILE, mode=\"a\",\n                               header=not os.path.exists(OUTFILE), index=False)\n\n                    print(f\"[{topo} z={z}] {mode_name} Th={theta} L={L} b={b} | {time.time()-start:.1f}s\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T16:00:50.270417Z","iopub.execute_input":"2026-01-15T16:00:50.270854Z"}},"outputs":[],"execution_count":null}]}