{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport networkx as nx\nimport pandas as pd\nimport time, os\nfrom collections import deque\nfrom numba import njit\nfrom joblib import Parallel, delayed\n\n# =========================================================\n# GRAPH BUILDERS & PRECOMPUTE\n# =========================================================\ndef make_graph(topo, N, z, seed):\n    if topo == \"BA\":\n        m = int(z / 2)\n        return nx.barabasi_albert_graph(N, m, seed=seed)\n    elif topo == \"ER\":\n        return nx.erdos_renyi_graph(N, z / (N - 1), seed=seed)\n    else:\n        raise ValueError(\"topo must be 'BA' or 'ER'\")\n\ndef make_influence_graph(G_g, corr, N, seed_perm=777):\n    if corr == \"max\": return G_g\n    rng = np.random.default_rng(seed_perm)\n    perm = np.arange(N, dtype=np.int32)\n    rng.shuffle(perm)\n    mapping = {int(i): int(perm[i]) for i in range(N)}\n    return nx.relabel_nodes(G_g, mapping)\n\ndef graph_to_csr(G):\n    G = nx.convert_node_labels_to_integers(G)\n    N = G.number_of_nodes()\n    adj_f = []\n    adj_o = [0]\n    for i in range(N):\n        neigh = list(G.neighbors(i))\n        adj_f.extend(neigh)\n        adj_o.append(len(adj_f))\n    return np.array(adj_f, dtype=np.int32), np.array(adj_o, dtype=np.int32), (np.array(adj_o[1:]) - np.array(adj_o[:-1])).astype(np.int32)\n\ndef build_influence_layers_bfs(G_i, N, Lmax):\n    adj = [list(G_i.neighbors(i)) for i in range(N)]\n    inf_indices = np.zeros((Lmax, N, N), dtype=np.int32)\n    inf_counts  = np.zeros((Lmax, N), dtype=np.int32)\n    for src in range(N):\n        dist = np.full(N, -1, dtype=np.int32)\n        dist[src] = 0\n        q = deque([src])\n        while q:\n            u = q.popleft()\n            if dist[u] == Lmax: continue\n            for v in adj[u]:\n                if dist[v] == -1:\n                    dist[v] = dist[u] + 1\n                    q.append(v)\n        for j in range(N):\n            d = dist[j]\n            if 0 < d <= Lmax:\n                l = d - 1\n                c = inf_counts[l, src]\n                inf_indices[l, src, c] = j\n                inf_counts[l, src] += 1\n    return inf_indices, inf_counts\n\n# =========================================================\n# NUMBA CORE - COST AS PERCENTAGE\n# =========================================================\n@njit(cache=True, fastmath=True)\ndef run_simulation_percentage_cost(\n    adj_f, adj_o, deg_f,\n    inf_indices, inf_counts,\n    alpha_weights,\n    theta, L, b,\n    steps, update_rule, K, vigilance_mode,\n    cost_percentage, # 0.1 = 10% coût, -0.1 = 10% récompense\n    seed):\n    \n    np.random.seed(seed)\n    N = deg_f.shape[0]\n\n    # Stratégies: 1=Coop, 0=Def\n    strat = np.random.randint(0, 2, N).astype(np.float64)\n    vig = np.zeros(N, dtype=np.float64)\n    for i in range(N):\n        if strat[i] == 1.0 and np.random.random() < 0.5:\n            vig[i] = 1.0\n\n    influences = np.empty(N, dtype=np.float64)\n    T_eff = np.empty(N, dtype=np.float64)\n    payoffs = np.empty(N, dtype=np.float64)\n    new_strat = np.empty(N, dtype=np.float64)\n\n    history_window = 300\n    burn_in = 1200\n    tol_std = 8e-4\n    history_c = np.zeros(history_window, dtype=np.float64)\n    filled = 0\n\n    for t in range(steps):\n        # A) Influence\n        for i in range(N):\n            I_i = 0.0\n            for l_idx in range(L):\n                cnt = inf_counts[l_idx, i]\n                if cnt > 0:\n                    v_sum = 0.0\n                    for k in range(cnt): v_sum += vig[inf_indices[l_idx, i, k]]\n                    I_i += alpha_weights[l_idx] * (v_sum / cnt)\n            influences[i] = I_i\n\n        # B) Vigilance\n        if vigilance_mode == 0: # amnesic\n            for i in range(N):\n                vig[i] = 1.0 if (strat[i] == 1.0 and influences[i] >= theta) else 0.0\n        else: # memory\n            for i in range(N):\n                if strat[i] == 0.0: vig[i] = 0.0\n                elif vig[i] == 0.0: vig[i] = 1.0 if influences[i] >= theta else 0.0\n\n        # C) Payoffs de base\n        for i in range(N):\n            T_eff[i] = 1.0 + (b - 1.0) * (1.0 - influences[i])\n            payoffs[i] = 0.0\n\n        for i in range(N):\n            start, end = adj_o[i], adj_o[i + 1]\n            if strat[i] == 1.0:\n                for idx in range(start, end):\n                    if strat[adj_f[idx]] == 1.0: payoffs[i] += 1.0\n            else:\n                Ti = T_eff[i]\n                for idx in range(start, end):\n                    if strat[adj_f[idx]] == 1.0: payoffs[i] += Ti\n\n        # --- CORRECTION & POURCENTAGE ---\n        # On applique le coût/récompense proportionnel au gain\n        for i in range(N):\n            if vig[i] == 1.0:\n                payoffs[i] *= (1.0 - cost_percentage)\n\n        # D) Update Rule\n        for i in range(N):\n            new_strat[i] = strat[i]\n            k_i = adj_o[i + 1] - adj_o[i]\n            if k_i == 0: continue\n            j = adj_f[adj_o[i] + np.random.randint(0, k_i)]\n            \n            if update_rule == 0: # Prop\n                if payoffs[j] > payoffs[i]:\n                    phi = max(k_i, deg_f[j]) * max(T_eff[i], T_eff[j])\n                    if phi > 0 and np.random.random() < (payoffs[j]-payoffs[i])/phi:\n                        new_strat[i] = strat[j]\n            else: # Fermi\n                k_noise = max(K, 1e-12)\n                p = 1.0 / (1.0 + np.exp((payoffs[i] - payoffs[j]) / k_noise))\n                if np.random.random() < p: new_strat[i] = strat[j]\n\n        strat[:] = new_strat[:]\n        rho = strat.mean()\n\n        if rho <= 0.0 or rho >= 1.0: return rho, vig.mean(), t, 0\n        history_c[t % history_window] = rho\n        filled = min(filled + 1, history_window)\n        if t > burn_in and t % 50 == 0 and filled == history_window:\n            if np.std(history_c) < tol_std: return history_c.mean(), vig.mean(), t, 1\n\n    return strat.mean(), vig.mean(), steps, 2\n\n# =========================================================\n# CONFIGURATION & RUN\n# =========================================================\nN = 500\nREPS = 50\nsteps = 15000 # Un peu plus long pour être \"carré\"\ntheta = 0.2\nL = 1\nK = 0.1\n# ICI : On met des pourcentages (0.1 = 10% de taxe, -0.1 = 10% de bonus)\ncosts_pct = [-0.1, -0.05, 0.0, 0.05, 0.1, 0.2,0.5]\nB_RANGE = np.around(np.arange(1.1, 2.1, 0.1), 1)\nTOPOS = [(\"ER\", 16),(\"BA\", 4)]\n\nOUTFILE = \"Comparaison_final_L1.csv\"\nIC_SEEDS = np.array([12345 + 1000*r for r in range(REPS)], dtype=np.int64)\n\nfor topo, z in TOPOS:\n    Gg = make_graph(topo, N, z, seed=42)\n    af, ao, deg = graph_to_csr(Gg)\n    inf_idx, inf_cnt = build_influence_layers_bfs(Gg, N, L)\n    alphas = np.array([0.5**l for l in range(L)]); alphas /= alphas.sum()\n\n    for cp in costs_pct:\n        for b in B_RANGE:\n            res = Parallel(n_jobs=-1)(delayed(run_simulation_percentage_cost)(\n                af, ao, deg, inf_idx, inf_cnt, alphas, theta, L, b, steps, 1, K, 1, cp, IC_SEEDS[r]\n            ) for r in range(REPS))\n            \n            rhos, vigs, tsts, reas = zip(*res)\n            pd.DataFrame([{\n                \"Topo\": topo, \"Z\": z, \"b\": b, \"Cost_Pct\": cp,\n                \"C_mean\": np.mean(rhos), \"C_std\": np.std(rhos),\n                \"V_mean\": np.mean(vigs), \"V_std\": np.std(vigs),\n                \"Tstop_mean\": np.mean(tsts), \"Stop_max_frac\": np.mean(np.array(reas) == 2)\n            }]).to_csv(OUTFILE, mode=\"a\", header=not os.path.exists(OUTFILE), index=False)\n            print(f\"[{topo} z={z}] Cost {cp*100}% b={b} done.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-20T11:34:13.933586Z","iopub.execute_input":"2026-01-20T11:34:13.934065Z","iopub.status.idle":"2026-01-20T11:34:15.840746Z","shell.execute_reply.started":"2026-01-20T11:34:13.934030Z","shell.execute_reply":"2026-01-20T11:34:15.839550Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3346659443.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mGg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mao\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_to_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0minf_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_influence_layers_bfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3346659443.py\u001b[0m in \u001b[0;36mbuild_influence_layers_bfs\u001b[0;34m(G_i, N, Lmax)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mLmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":2}]}